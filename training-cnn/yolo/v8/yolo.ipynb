{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5aa675e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transform\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from torchvision.datasets import ImageFolder\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0dc9d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAugmentedDataset(ImageFolder):\n",
    "\n",
    "    # constructor\n",
    "    def __init__(self, root, transforms_dict, default_transforms=None):\n",
    "        super().__init__(root)\n",
    "        self.transform_dict = transforms_dict\n",
    "        self.default_transform = default_transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        sample = self.loader(path)\n",
    "\n",
    "        class_name = self.classes[target]\n",
    "        transform = self.transform_dict.get(class_name, self.default_transform)\n",
    "\n",
    "        if transform:\n",
    "            sample = transform(sample)\n",
    "        return sample, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b973556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sample counts per class:\n",
      "algal_spot: 1465\n",
      "brown-blight: 1397\n",
      "gray-blight: 1220\n",
      "healthy: 755\n",
      "helopeltis: 1351\n",
      "leaf-rust: 1600\n",
      "red-rust: 417\n",
      "red-spider-infested: 732\n",
      "red-spot: 755\n",
      "white-spot: 233\n",
      "Validation sample counts per class:\n",
      "algal_spot: 100\n",
      "brown-blight: 60\n",
      "gray-blight: 105\n",
      "healthy: 45\n",
      "helopeltis: 155\n",
      "leaf-rust: 67\n",
      "red-rust: 5\n",
      "red-spider-infested: 14\n",
      "red-spot: 45\n",
      "white-spot: 32\n",
      "Class detected: ['algal_spot', 'brown-blight', 'gray-blight', 'healthy', 'helopeltis', 'leaf-rust', 'red-rust', 'red-spider-infested', 'red-spot', 'white-spot']\n",
      "Augmentation summary per class:\n",
      "algal_spot      ‚Üí Default\n",
      "brown-blight    ‚Üí Default\n",
      "gray-blight     ‚Üí Default\n",
      "healthy         ‚Üí Default\n",
      "helopeltis      ‚Üí Default\n",
      "leaf-rust       ‚Üí Default\n",
      "red-rust        ‚Üí Default\n",
      "red-spider-infested ‚Üí Default\n",
      "red-spot        ‚Üí Strong\n",
      "white-spot      ‚Üí Default\n",
      "Total train batches: 1241\n",
      "Total validation batches: 79\n"
     ]
    }
   ],
   "source": [
    "default_transform = transform.Compose([\n",
    "    transform.Resize(224),\n",
    "    transform.CenterCrop(224),\n",
    "    transform.ToTensor(),\n",
    "    transform.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "strong_transform = transform.Compose([\n",
    "    transform.Resize(224),\n",
    "    transform.RandomResizedCrop(224),\n",
    "    transform.RandomHorizontalFlip(),\n",
    "    transform.RandomRotation(30),\n",
    "    transform.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "    transform.ToTensor(),\n",
    "    transform.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "small_classes = ['red-spot']\n",
    "transform_dict = {cls: strong_transform for cls in small_classes}\n",
    "\n",
    "# load dataset beserta transform-nya\n",
    "train_dataset = CustomAugmentedDataset(root='../../../dataset/Train/', transforms_dict=transform_dict, default_transforms=default_transform)\n",
    "val_dataset = CustomAugmentedDataset(root='../../../dataset/Valid/', transforms_dict=transform_dict, default_transforms=default_transform)\n",
    "\n",
    "valid_classes = ['algal_spot', 'brown-blight', 'gray-blight', 'healthy', 'helopeltis', \n",
    "                 'leaf-rust', 'red-rust', 'red-spider-infested', 'red-spot', 'white-spot']\n",
    "train_class_to_idx = {cls: idx for idx, cls in enumerate(valid_classes) if cls in train_dataset.classes}\n",
    "train_samples = [(path, train_class_to_idx[train_dataset.classes[label]]) \n",
    "                 for path, label in train_dataset.samples \n",
    "                 if train_dataset.classes[label] in valid_classes]\n",
    "val_samples = [(path, train_class_to_idx[val_dataset.classes[label]]) \n",
    "               for path, label in val_dataset.samples \n",
    "               if val_dataset.classes[label] in valid_classes]\n",
    "\n",
    "if not train_samples or not val_samples:\n",
    "    raise ValueError(\"No samples match the 10 classes. Check dataset subfolders.\")\n",
    "\n",
    "train_dataset.samples = train_samples\n",
    "train_dataset.classes = valid_classes\n",
    "train_dataset.class_to_idx = train_class_to_idx\n",
    "val_dataset.samples = val_samples\n",
    "val_dataset.classes = valid_classes\n",
    "val_dataset.class_to_idx = train_class_to_idx\n",
    "\n",
    "class_counts = np.bincount([label for _, label in train_dataset.samples])\n",
    "class_weight = 1. / torch.tensor(class_counts, dtype=torch.float)\n",
    "\n",
    "sample_weights = [class_weight[label] for _, label in train_dataset.samples]\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, sampler=sampler, num_workers=6, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, num_workers=4, shuffle=False)\n",
    "\n",
    "train_counts = Counter(train_dataset.classes[label] for _, label in train_samples)\n",
    "val_counts = Counter(val_dataset.classes[label] for _, label in val_samples)\n",
    "print(\"Train sample counts per class:\")\n",
    "for cls in valid_classes:\n",
    "    print(f\"{cls}: {train_counts.get(cls, 0)}\")\n",
    "print(\"Validation sample counts per class:\")\n",
    "for cls in valid_classes:\n",
    "    print(f\"{cls}: {val_counts.get(cls, 0)}\")\n",
    "\n",
    "\n",
    "print(f\"Class detected: {train_dataset.classes}\")\n",
    "\n",
    "print(\"Augmentation summary per class:\")\n",
    "for cls in train_dataset.classes:\n",
    "    print(f\"{cls.ljust(15)} ‚Üí {'Strong' if cls in transform_dict else 'Default'}\")\n",
    "\n",
    "print(f\"Total train batches: {len(train_dataloader)}\")\n",
    "print(f\"Total validation batches: {len(val_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78337541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classify\n"
     ]
    }
   ],
   "source": [
    "# Load YOLOv10 classification model with pre-trained weights\n",
    "model = YOLO(\"yolov8n-cls.pt\", task=\"classify\")  # Nano model, pre-trained on ImageNet\n",
    "print(model.task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14d4b62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is cuda available? True\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('is cuda available?', torch.cuda.is_available())\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aaf102ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 1.0, 1.0]).to(device)  # Lower weight for red-spider-infested\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dff85cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "training_args = {\n",
    "    'data': '../../../dataset/Train',\n",
    "    'epochs': num_epochs,\n",
    "    # 'nc': 10,\n",
    "    # 'names': ['algal_spot', 'brown-blight', 'gray-blight', 'healthy', 'helopeltis', 'leaf-rust', 'red-rust', 'red-spider-infested', 'red-spot', 'white-spot'],\n",
    "    'imgsz': 224,\n",
    "    'batch': 8,\n",
    "    'device': 0 if torch.cuda.is_available() else 'cpu',\n",
    "    'workers': 0,\n",
    "    'project': './runs/train',\n",
    "    'name': 'yolov8n_cls',\n",
    "    'exist_ok': True,\n",
    "    'pretrained': True,\n",
    "    'optimizer': 'Adam',\n",
    "    'lr0': 0.0001,\n",
    "    'patience': 50,\n",
    "    # Augmentation settings (respecting red-spot's strong augmentation)\n",
    "    'hsv_h': 0.015,  # Default hue\n",
    "    'hsv_s': 0.7,    # Default saturation\n",
    "    'hsv_v': 0.4,    # Default value\n",
    "    'degrees': 10.0,  # Rotation\n",
    "    'translate': 0.1, # Translation\n",
    "    'scale': 0.5,    # Zoom\n",
    "    'shear': 0.0,\n",
    "    'flipud': 0.0,   # Vertical flip\n",
    "    'fliplr': 0.5,   # Horizontal flip\n",
    "    'mosaic': 0.0,   # Disable mosaic for classification\n",
    "    'mixup': 0.0,    # Disable mixup\n",
    "    'task':'classify',\n",
    "    # 'cls_weight': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 1.0, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a93a2be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "['leaf-rust', 'brown-blight', 'red-rust', 'white-spot', 'healthy', 'gray-blight', 'helopeltis', 'red-spot', 'algal_spot', 'red-spider-infested']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.exists(\"../../../dataset/Valid/\"))  # Should print True\n",
    "print(os.listdir(\"../../../dataset/Valid/\"))  # Should list class folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4a36fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.119 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce GTX 1650 SUPER, 3875MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=../../../dataset/Train, epochs=15, time=None, patience=50, batch=8, imgsz=224, save=True, save_period=-1, cache=False, device=0, workers=0, project=./runs/train, name=yolov8n_cls, exist_ok=True, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=10.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.0, cutmix=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/train/yolov8n_cls\n",
      "WARNING ‚ö†Ô∏è Dataset 'split=train' not found at /home/oz31/code/personal/python/training-skripsi/dataset/Train/train\n",
      "Found 9518 images in subdirectories. Attempting to split...\n",
      "Splitting /home/oz31/code/personal/python/training-skripsi/dataset/Train (10 classes, 9925 images) into 80% train, 20% val...\n",
      "Split complete in /home/oz31/code/personal/python/training-skripsi/dataset/Train_split ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /home/oz31/code/personal/python/training-skripsi/dataset/Train_split/train... found 7937 images in 10 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /home/oz31/code/personal/python/training-skripsi/dataset/Train_split/val... found 1988 images in 10 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=1000 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    343050  ultralytics.nn.modules.head.Classify         [256, 10]                     \n",
      "YOLOv8n-cls summary: 56 layers, 1,451,098 parameters, 1,451,098 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "WARNING ‚ö†Ô∏è \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed ‚ùå. AMP training on NVIDIA GeForce GTX 1650 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 313.5¬±77.6 MB/s, size: 6.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/oz31/code/personal/python/training-skripsi/dataset/Train_split/train... 7937 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7937/7937 [00:00<00:00, 8042.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/oz31/code/personal/python/training-skripsi/dataset/Train_split/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 250.6¬±72.5 MB/s, size: 4.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/oz31/code/personal/python/training-skripsi/dataset/Train_split/val... 1988 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1988/1988 [00:00<00:00, 7774.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/oz31/code/personal/python/training-skripsi/dataset/Train_split/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0001, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/yolov8n_cls\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       1/15     0.309G      1.278          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 993/993 [01:00<00:00, 16.39it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:08<00:00, 14.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.744      0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/15     0.316G     0.8966          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 993/993 [00:59<00:00, 16.59it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:08<00:00, 14.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.808      0.998\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       3/15     0.324G     0.7268          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 993/993 [00:59<00:00, 16.68it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:08<00:00, 14.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.837      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       4/15     0.334G     0.6636          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 993/993 [00:59<00:00, 16.76it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:08<00:00, 14.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.843      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/15     0.342G     0.6274          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 993/993 [00:59<00:00, 16.74it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:08<00:00, 14.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.852      0.998\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       6/15      0.35G     0.5913          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 993/993 [00:59<00:00, 16.74it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:08<00:00, 14.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.866      0.999\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       7/15     0.357G     0.5729          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 993/993 [00:59<00:00, 16.78it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:08<00:00, 14.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.857      0.998\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       8/15     0.367G     0.5449          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 993/993 [00:59<00:00, 16.73it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:08<00:00, 14.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.864      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/15     0.375G     0.5209          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 993/993 [00:59<00:00, 16.71it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:08<00:00, 14.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.862      0.998\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      10/15     0.381G     0.5382          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 993/993 [00:59<00:00, 16.81it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:08<00:00, 14.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.868      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/15     0.391G     0.5208          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 993/993 [00:59<00:00, 16.80it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:08<00:00, 14.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.866      0.998\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      12/15     0.398G     0.5058          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 993/993 [00:59<00:00, 16.77it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:08<00:00, 14.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.876      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/15     0.408G     0.5085          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 993/993 [00:59<00:00, 16.75it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:08<00:00, 14.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.873      0.998\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      14/15     0.416G     0.5057          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 993/993 [00:59<00:00, 16.73it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:08<00:00, 14.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.875      0.998\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      15/15     0.424G     0.4909          1        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 993/993 [00:59<00:00, 16.75it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:08<00:00, 14.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.872      0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "15 epochs completed in 0.283 hours.\n",
      "Optimizer stripped from runs/train/yolov8n_cls/weights/last.pt, 3.0MB\n",
      "Optimizer stripped from runs/train/yolov8n_cls/weights/best.pt, 3.0MB\n",
      "\n",
      "Validating runs/train/yolov8n_cls/weights/best.pt...\n",
      "Ultralytics 8.3.119 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce GTX 1650 SUPER, 3875MiB)\n",
      "YOLOv8n-cls summary (fused): 30 layers, 1,447,690 parameters, 0 gradients, 3.3 GFLOPs\n",
      "WARNING ‚ö†Ô∏è Dataset 'split=train' not found at /home/oz31/code/personal/python/training-skripsi/dataset/Train/train\n",
      "Found 9518 images in subdirectories. Attempting to split...\n",
      "Splitting /home/oz31/code/personal/python/training-skripsi/dataset/Train (10 classes, 9925 images) into 80% train, 20% val...\n",
      "Split complete in /home/oz31/code/personal/python/training-skripsi/dataset/Train_split ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /home/oz31/code/personal/python/training-skripsi/dataset/Train_split/train... found 9506 images in 10 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /home/oz31/code/personal/python/training-skripsi/dataset/Train_split/val... found 3557 images in 10 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:08<00:00, 14.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.876      0.998\n",
      "Speed: 0.1ms preprocess, 0.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/train/yolov8n_cls\u001b[0m\n",
      "result model train YOLO v10: ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
      "\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7acbe58663f0>\n",
      "curves: []\n",
      "curves_results: []\n",
      "fitness: 0.9373742341995239\n",
      "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
      "results_dict: {'metrics/accuracy_top1': 0.8762575387954712, 'metrics/accuracy_top5': 0.9984909296035767, 'fitness': 0.9373742341995239}\n",
      "save_dir: PosixPath('runs/train/yolov8n_cls')\n",
      "speed: {'preprocess': 0.06103980985806362, 'inference': 0.3656032771615197, 'loss': 0.0003048511073517528, 'postprocess': 0.000496410968519061}\n",
      "task: 'classify'\n",
      "top1: 0.8762575387954712\n",
      "top5: 0.9984909296035767\n"
     ]
    }
   ],
   "source": [
    "results = model.train(**training_args)\n",
    "print(f\"result model train YOLO v10: {results}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
