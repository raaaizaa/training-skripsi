{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "c6a8198d",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from ultralytics import YOLO"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "f2710135",
            "metadata": {},
            "outputs": [],
            "source": [
                "NUM_CLASSES = 9\n",
                "NUM_WORKERS = 2\n",
                "NUM_EPOCHS  = 30\n",
                "BATCH_SIZE = 8\n",
                "\n",
                "IMAGE_SIZE = 224\n",
                "LEARNING_RATE = 1e-3"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "f990875b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-cls.pt to 'yolo11n-cls.pt'...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.52M/5.52M [00:04<00:00, 1.29MB/s]\n"
                    ]
                }
            ],
            "source": [
                "pretrained_model_path = 'yolo11n-cls.pt'\n",
                "model = YOLO(model=pretrained_model_path, task='classify')\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "model = model.to(device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "baa5624c",
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset_path = '../../../../dataset'\n",
                "name = 'yolov11_cls'\n",
                "project_path = './runs/train'\n",
                "\n",
                "training_args = {\n",
                "    # train configuration\n",
                "    'data': dataset_path,\n",
                "    'project': project_path,\n",
                "    'name': name,\n",
                "\n",
                "    'pretrained': True,\n",
                "    'optimizer': 'Adam',\n",
                "    'mode': 'train',\n",
                "    'device': device,\n",
                "    'task': 'classify',\n",
                "    'exist_ok': True,\n",
                "\n",
                "    'epochs': NUM_EPOCHS,\n",
                "    'workers': NUM_WORKERS,\n",
                "    'batch': BATCH_SIZE,\n",
                "    'lr0': LEARNING_RATE,\n",
                "    'patience': 50,\n",
                "\n",
                "     # hyperparameter setting\n",
                "    'imgsz': IMAGE_SIZE,\n",
                "    'hsv_v': 0.2,\n",
                "    'degrees': 15.0,\n",
                "    'translate': 0.1,\n",
                "    'scale': 0.5,\n",
                "    'shear': 0.0,\n",
                "    'flipud': 0.5,\n",
                "    'fliplr': 0.5,\n",
                "    'mosaic': 0.0,\n",
                "    'mixup': 0.0,\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "6ad66c47",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "New https://pypi.org/project/ultralytics/8.3.174 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
                        "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../../../../dataset, degrees=15.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.2, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n-cls.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=yolov11_cls, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=50, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=./runs/train, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/train/yolov11_cls, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
                        "\u001b[34m\u001b[1mtrain:\u001b[0m /home/oz31/code/personal/python/training-skripsi/dataset/train... found 4626 images in 9 classes âœ… \n",
                        "\u001b[34m\u001b[1mval:\u001b[0m /home/oz31/code/personal/python/training-skripsi/dataset/val... found 990 images in 9 classes âœ… \n",
                        "\u001b[34m\u001b[1mtest:\u001b[0m /home/oz31/code/personal/python/training-skripsi/dataset/test... found 995 images in 9 classes âœ… \n",
                        "Overriding model.yaml nc=80 with nc=9\n",
                        "\n",
                        "                   from  n    params  module                                       arguments                     \n",
                        "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
                        "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
                        "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
                        "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
                        "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
                        "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
                        "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
                        "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
                        "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
                        "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
                        " 10                  -1  1    341769  ultralytics.nn.modules.head.Classify         [256, 9]                      \n",
                        "YOLO11n-cls summary: 86 layers, 1,542,633 parameters, 1,542,633 gradients, 3.3 GFLOPs\n",
                        "Transferred 234/236 items from pretrained weights\n",
                        "WARNING âš ï¸ \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed âŒ. AMP training on NVIDIA GeForce GTX 1650 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
                        "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 4611.3Â±993.2 MB/s, size: 149.8 KB)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/oz31/code/personal/python/training-skripsi/dataset/train... 4626 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4626/4626 [00:00<?, ?it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1094.0Â±110.6 MB/s, size: 174.1 KB)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/oz31/code/personal/python/training-skripsi/dataset/val... 990 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 990/990 [00:00<?, ?it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.937) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
                        "Image sizes 224 train, 224 val\n",
                        "Using 2 dataloader workers\n",
                        "Logging results to \u001b[1mruns/train/yolov11_cls\u001b[0m\n",
                        "Starting training for 30 epochs...\n",
                        "\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all       0.91      0.998\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all      0.938          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all      0.952          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all      0.957          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all      0.959          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all      0.967          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all      0.976          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all      0.979          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all      0.979          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all      0.973          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all       0.98          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all      0.984          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all       0.98          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all      0.982          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all      0.984          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all       0.98          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all      0.986          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all      0.986          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all      0.988          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all      0.988          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all      0.989          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all      0.987          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all       0.99          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all      0.989          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all      0.991          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all       0.99          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all       0.99          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all      0.989          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all      0.992          1\n",
                        "      Epoch    GPU_mem       loss  Instances       Size\n",
                        "                   all      0.991          1\n",
                        "\n",
                        "30 epochs completed in 0.307 hours.\n",
                        "Optimizer stripped from runs/train/yolov11_cls/weights/last.pt, 3.2MB\n",
                        "Optimizer stripped from runs/train/yolov11_cls/weights/best.pt, 3.2MB\n",
                        "Validating runs/train/yolov11_cls/weights/best.pt...\n",
                        "Ultralytics 8.3.134 ðŸš€ Python-3.12.3 torch-2.7.0+cu126 CUDA:0 (NVIDIA GeForce GTX 1650 SUPER, 3875MiB)\n",
                        "YOLO11n-cls summary (fused): 47 layers, 1,537,553 parameters, 0 gradients, 3.2 GFLOPs\n",
                        "\n",
                        "test: None...\n",
                        "                   all      0.992          1\n",
                        "Speed: 0.1ms preprocess, 0.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
                        "Results saved to \u001b[1mruns/train/yolov11_cls\u001b[0m\n",
                        "result model train YOLO v11: ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
                        "\n",
                        "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x744eec3ab140>\n",
                        "curves: []\n",
                        "curves_results: []\n",
                        "fitness: 0.9959983229637146\n",
                        "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
                        "results_dict: {'metrics/accuracy_top1': 0.9919966459274292, 'metrics/accuracy_top5': 1.0, 'fitness': 0.9959983229637146}\n",
                        "save_dir: PosixPath('runs/train/yolov11_cls')\n",
                        "speed: {'preprocess': 0.06197757034447455, 'inference': 0.41064175652820006, 'loss': 0.0002578820561141889, 'postprocess': 0.0003813243458648858}\n",
                        "task: 'classify'\n",
                        "top1: 0.9919966459274292\n",
                        "top5: 1.0\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "results = model.train(**training_args)\n",
                "print(f\"result model train YOLO v11: {results}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv (3.12.3)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}