{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transform\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAugmentedDataset(ImageFolder):\n",
    "    \n",
    "    # root: folder dataset, transform_dict: nama class & augmentasi khusus\n",
    "    def __init__(self, root, transform_dict, default_transform=None):\n",
    "        super().__init__(root)\n",
    "        self.transform_dict = transform_dict\n",
    "        self.default_transform = default_transform\n",
    "    \n",
    "    # ambil gambar dari class, apply augmentasi, return gambar hasil augmentasi\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        sample = self.loader(path)\n",
    "\n",
    "        class_name = self.classes[target]\n",
    "        transform = self.transform_dict.get(class_name, self.default_transform)\n",
    "\n",
    "        sample = transform(sample)\n",
    "\n",
    "        return sample, target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_transform = transform.Compose([\n",
    "    transform.Resize(256),\n",
    "    transform.CenterCrop(224),\n",
    "    transform.ToTensor(),\n",
    "    transform.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "strong_transform = transform.Compose([\n",
    "    transform.Resize(256),\n",
    "    transform.RandomResizedCrop(224),\n",
    "    transform.RandomHorizontalFlip(),\n",
    "    transform.RandomRotation(30),\n",
    "    transform.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "    transform.ToTensor(),\n",
    "    transform.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes detected: ['algal_spot', 'brown-blight', 'gray-blight', 'healthy', 'helopeltis', 'leaf-rust', 'red-rust', 'red-spider-infested', 'red-spot', 'white-spot']\n",
      "Augmentation summary per class:\n",
      "algal_spot      → Default\n",
      "brown-blight    → Default\n",
      "gray-blight     → Default\n",
      "healthy         → Default\n",
      "helopeltis      → Default\n",
      "leaf-rust       → Default\n",
      "red-rust        → Default\n",
      "red-spider-infested → Default\n",
      "red-spot        → Strong\n",
      "white-spot      → Default\n"
     ]
    }
   ],
   "source": [
    "# deteksi augmentasi khusus buat red spot\n",
    "small_classes = ['red-spot']\n",
    "transform_dict = {cls: strong_transform for cls in small_classes}\n",
    "\n",
    "# load dataset beserta transform-nya\n",
    "train_dataset = CustomAugmentedDataset(root='../../dataset/Train/', transform_dict=transform_dict, default_transform=default_transform)\n",
    "val_dataset = CustomAugmentedDataset(root='../../dataset/Valid/', transform_dict=transform_dict, default_transform=default_transform)\n",
    "\n",
    "# class count\n",
    "class_counts = np.bincount([label for _, label in train_dataset.samples])\n",
    "class_weights = 1. / torch.tensor(class_counts, dtype=torch.float)\n",
    "\n",
    "# sampler buat ngatasin class imbalance dengan cara ngasih probabilitas sampling lebih tinggi ke class yang punya data sedikit\n",
    "sample_weights = [class_weights[label] for _, label in train_dataset.samples]\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, num_workers=0, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Classes detected: {train_dataset.classes}\")\n",
    "\n",
    "print(\"Augmentation summary per class:\")\n",
    "for cls in train_dataset.classes:\n",
    "    print(f\"{cls.ljust(15)} → {'Strong' if cls in transform_dict else 'Default'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Raiza Rahman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Raiza Rahman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import model\n",
    "model = models.vgg16(pretrained=True) # GANTI SESUAI MODEL YANG MAU DI-TRAIN\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is cuda available? True\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "# ganti layer terakhir biar disesuain sama jumlah class di dataset\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes) # ADJUST SESUAI MODEL\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('is cuda available?', torch.cuda.is_available())\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function buat klasifikasi multi-class\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches: 2637\n",
      "Starting Epoch 1/30\n",
      "masuk looping\n",
      "loop!\n",
      "Processing batch 1/2637\n",
      "loop!\n",
      "loop!\n",
      "loop!\n",
      "loop!\n",
      "loop!\n",
      "loop!\n",
      "loop!\n",
      "loop!\n",
      "loop!\n",
      "loop!\n",
      "loop!\n",
      "loop!\n",
      "loop!\n",
      "loop!\n",
      "loop!\n",
      "loop!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Raiza Rahman\\training-skripsi\\training-cnn\\vggnet\\vggnet16.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Raiza%20Rahman/training-skripsi/training-cnn/vggnet/vggnet16.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Raiza%20Rahman/training-skripsi/training-cnn/vggnet/vggnet16.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Raiza%20Rahman/training-skripsi/training-cnn/vggnet/vggnet16.ipynb#X10sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Raiza%20Rahman/training-skripsi/training-cnn/vggnet/vggnet16.ipynb#X10sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m _, predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs, \u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Raiza%20Rahman/training-skripsi/training-cnn/vggnet/vggnet16.ipynb#X10sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (predicted \u001b[39m==\u001b[39m labels)\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "print(f\"Total batches: {len(train_dataloader)}\")\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Starting Epoch {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    print('masuk looping')\n",
    "    for batch_idx, (images, labels) in enumerate(train_dataloader):\n",
    "        print('loop!')\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Processing batch {batch_idx+1}/{len(train_dataloader)}\")\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / len(train_dataloader)\n",
    "    train_accuracy = (correct / total) * 100\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    val_accuracy = (val_correct / val_total) * 100\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"vggnet16.pth\")\n",
    "print(\"Model saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
