{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transform\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 2\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transform.Compose([\n",
    "    transform.RandomResizedCrop(IMAGE_SIZE, scale=(0.8, 1.0)),\n",
    "    transform.RandomHorizontalFlip(),\n",
    "    transform.RandomVerticalFlip(),\n",
    "    transform.RandomRotation(15), \n",
    "    transform.ColorJitter(brightness=0.2, contrast=0.2), \n",
    "    transform.ToTensor(),   \n",
    "    transform.Normalize(MEAN, STD) \n",
    "])\n",
    "\n",
    "val_transforms = transform.Compose([\n",
    "    transform.Resize(256),\n",
    "    transform.CenterCrop(IMAGE_SIZE), \n",
    "    transform.ToTensor(),\n",
    "    transform.Normalize(MEAN, STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes detected: ['algal_spot', 'brown_blight', 'gray_blight', 'healthy', 'helopeltis', 'red-rust', 'red-spider-infested', 'red_spot', 'white-spot']\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ImageFolder(root='../../dataset-dapa//Train/', transform=train_transforms)\n",
    "val_dataset = ImageFolder(root='../../dataset-dapa/val/', transform=train_transforms)\n",
    "\n",
    "class_counts = np.bincount([label for _, label in train_dataset.samples])\n",
    "class_weights = 1. / torch.tensor(class_counts, dtype=torch.float)\n",
    "\n",
    "sample_weights = [class_weights[label] for _, label in train_dataset.samples]\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Classes detected: {train_dataset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace=True)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace=True)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace=True)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace=True)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace=True)\n",
       "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): ReLU(inplace=True)\n",
       "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace=True)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): ReLU(inplace=True)\n",
       "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (25): ReLU(inplace=True)\n",
       "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (27): ReLU(inplace=True)\n",
       "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (29): ReLU(inplace=True)\n",
       "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "features = model.features\n",
    "features.requires_grad_(False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is cuda available? True\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('is cuda available?', torch.cuda.is_available())\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += images.size(0)\n",
    "    return running_loss/total, correct/total\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += images.size(0)\n",
    "    return val_loss/total, correct/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches: 290\n",
      "Epoch 1/30: Train loss 1.7899, acc 0.4658 | Val   loss 1.1541, acc 0.6313\n",
      "Epoch 2/30: Train loss 1.3641, acc 0.6366 | Val   loss 0.9238, acc 0.7121\n",
      "Epoch 3/30: Train loss 1.1870, acc 0.6807 | Val   loss 0.6490, acc 0.7909\n",
      "Epoch 4/30: Train loss 1.1241, acc 0.7105 | Val   loss 0.6187, acc 0.8061\n",
      "Epoch 5/30: Train loss 1.0491, acc 0.7134 | Val   loss 0.5781, acc 0.8192\n",
      "Epoch 6/30: Train loss 0.9714, acc 0.7391 | Val   loss 0.5577, acc 0.8384\n",
      "Epoch 7/30: Train loss 0.9754, acc 0.7466 | Val   loss 0.5390, acc 0.8515\n",
      "Epoch 8/30: Train loss 0.9675, acc 0.7402 | Val   loss 0.6355, acc 0.8172\n",
      "Epoch 9/30: Train loss 0.8921, acc 0.7564 | Val   loss 0.6518, acc 0.8131\n",
      "Epoch 10/30: Train loss 0.8737, acc 0.7672 | Val   loss 0.5450, acc 0.8545\n",
      "Epoch 11/30: Train loss 0.9088, acc 0.7551 | Val   loss 0.5490, acc 0.8495\n",
      "Epoch 12/30: Train loss 0.7599, acc 0.7890 | Val   loss 0.5822, acc 0.8354\n",
      "Epoch 13/30: Train loss 0.7994, acc 0.7901 | Val   loss 0.4655, acc 0.8707\n",
      "Epoch 14/30: Train loss 0.8067, acc 0.7741 | Val   loss 0.5176, acc 0.8576\n",
      "Epoch 15/30: Train loss 0.7626, acc 0.7996 | Val   loss 0.4336, acc 0.8687\n",
      "Epoch 16/30: Train loss 0.7722, acc 0.7974 | Val   loss 0.4139, acc 0.8697\n",
      "Epoch 17/30: Train loss 0.7455, acc 0.8016 | Val   loss 0.4461, acc 0.8778\n",
      "Epoch 18/30: Train loss 0.7065, acc 0.8087 | Val   loss 0.3941, acc 0.8848\n",
      "Epoch 19/30: Train loss 0.7439, acc 0.7879 | Val   loss 0.4691, acc 0.8747\n",
      "Epoch 20/30: Train loss 0.7643, acc 0.8018 | Val   loss 0.5497, acc 0.8818\n",
      "Epoch 21/30: Train loss 0.7996, acc 0.8000 | Val   loss 0.4203, acc 0.8828\n",
      "Epoch 22/30: Train loss 0.7822, acc 0.7985 | Val   loss 0.4484, acc 0.8778\n",
      "Epoch 23/30: Train loss 0.6455, acc 0.8165 | Val   loss 0.3757, acc 0.8798\n",
      "Epoch 24/30: Train loss 0.7109, acc 0.8132 | Val   loss 0.3812, acc 0.8869\n",
      "Epoch 25/30: Train loss 0.6872, acc 0.8158 | Val   loss 0.4428, acc 0.8838\n",
      "Epoch 26/30: Train loss 0.6643, acc 0.8137 | Val   loss 0.4709, acc 0.8586\n",
      "Epoch 27/30: Train loss 0.6183, acc 0.8307 | Val   loss 0.4509, acc 0.8636\n",
      "Epoch 28/30: Train loss 0.6627, acc 0.8232 | Val   loss 0.4081, acc 0.8869\n",
      "Epoch 29/30: Train loss 0.7195, acc 0.8236 | Val   loss 0.3702, acc 0.8909\n",
      "Epoch 30/30: Train loss 0.6025, acc 0.8441 | Val   loss 0.3782, acc 0.8828\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "print(f\"Total batches: {len(train_loader)}\")\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc     = validate(model, val_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: \"\n",
    "          f\"Train loss {train_loss:.4f}, acc {train_acc:.4f} | \"\n",
    "          f\"Val   loss {val_loss:.4f}, acc {val_acc:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_vgg16.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"vggnet16.pth\")\n",
    "print(\"Model saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
