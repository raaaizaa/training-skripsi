{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transform\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAugmentedDataset(ImageFolder):\n",
    "    \n",
    "    # root: folder dataset, transform_dict: nama class & augmentasi khusus\n",
    "    def __init__(self, root, transform_dict, default_transform=None):\n",
    "        super().__init__(root)\n",
    "        self.transform_dict = transform_dict\n",
    "        self.default_transform = default_transform\n",
    "    \n",
    "    # ambil gambar dari class, apply augmentasi, return gambar hasil augmentasi\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        sample = self.loader(path)\n",
    "    \n",
    "        class_name = self.classes[target]\n",
    "        transform = self.transform_dict.get(class_name, self.default_transform)\n",
    "\n",
    "        if transform:\n",
    "            sample = transform(sample)\n",
    "        \n",
    "        return sample, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_transform = transform.Compose([\n",
    "    transform.Resize(256),\n",
    "    transform.CenterCrop(224),\n",
    "    transform.ToTensor(),\n",
    "    transform.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "strong_transform = transform.Compose([\n",
    "    transform.Resize(256),\n",
    "    transform.RandomResizedCrop(224),\n",
    "    transform.RandomHorizontalFlip(),\n",
    "    transform.RandomRotation(30),\n",
    "    transform.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "    transform.ToTensor(),\n",
    "    transform.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes detected: ['algal_spot', 'brown-blight', 'gray-blight', 'healthy', 'helopeltis', 'leaf-rust', 'red-rust', 'red-spider-infested', 'red-spot', 'white-spot']\n",
      "Augmentation summary per class:\n",
      "algal_spot      → Default\n",
      "brown-blight    → Default\n",
      "gray-blight     → Default\n",
      "healthy         → Default\n",
      "helopeltis      → Default\n",
      "leaf-rust       → Default\n",
      "red-rust        → Default\n",
      "red-spider-infested → Default\n",
      "red-spot        → Strong\n",
      "white-spot      → Default\n"
     ]
    }
   ],
   "source": [
    "# deteksi augmentasi khusus buat red spot\n",
    "small_classes = ['red-spot']\n",
    "transform_dict = {cls: strong_transform for cls in small_classes}\n",
    "\n",
    "# load dataset beserta transform-nya\n",
    "train_dataset = CustomAugmentedDataset(root='../../dataset/Train/', transform_dict=transform_dict, default_transform=default_transform)\n",
    "val_dataset = CustomAugmentedDataset(root='../../dataset/Valid/', transform_dict=transform_dict, default_transform=default_transform)\n",
    "\n",
    "# class count\n",
    "class_counts = np.bincount([label for _, label in train_dataset.samples])\n",
    "class_weights = 1. / torch.tensor(class_counts, dtype=torch.float)\n",
    "\n",
    "# sampler buat ngatasin class imbalance dengan cara ngasih probabilitas sampling lebih tinggi ke class yang punya data sedikit\n",
    "sample_weights = [class_weights[label] for _, label in train_dataset.samples]\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, sampler=sampler, num_workers=0, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Classes detected: {train_dataset.classes}\")\n",
    "\n",
    "print(\"Augmentation summary per class:\")\n",
    "for cls in train_dataset.classes:\n",
    "    print(f\"{cls.ljust(15)} → {'Strong' if cls in transform_dict else 'Default'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Raiza Rahman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Raiza Rahman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import model\n",
    "model = models.vgg19(pretrained=True) # GANTI SESUAI MODEL YANG MAU DI-TRAIN\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is cuda available? True\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "# ganti layer terakhir biar disesuain sama jumlah class di dataset\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes) # ADJUST SESUAI MODEL\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('is cuda available?', torch.cuda.is_available())\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function buat klasifikasi multi-class\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches: 1319\n",
      "Starting Epoch 1/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 1/30, Loss: 0.6332, Accuracy: 77.31%\n",
      "Validation Loss: 0.5858, Accuracy: 75.96%\n",
      "Starting Epoch 2/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 2/30, Loss: 0.3434, Accuracy: 88.01%\n",
      "Validation Loss: 0.7089, Accuracy: 81.21%\n",
      "Starting Epoch 3/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 3/30, Loss: 0.3093, Accuracy: 89.10%\n",
      "Validation Loss: 0.9879, Accuracy: 71.82%\n",
      "Starting Epoch 4/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 4/30, Loss: 0.2533, Accuracy: 90.98%\n",
      "Validation Loss: 0.6125, Accuracy: 79.46%\n",
      "Starting Epoch 5/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 5/30, Loss: 0.2168, Accuracy: 92.37%\n",
      "Validation Loss: 0.8601, Accuracy: 82.17%\n",
      "Starting Epoch 6/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 6/30, Loss: 0.2162, Accuracy: 92.61%\n",
      "Validation Loss: 0.6158, Accuracy: 85.35%\n",
      "Starting Epoch 7/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 7/30, Loss: 0.1993, Accuracy: 93.21%\n",
      "Validation Loss: 0.5880, Accuracy: 77.71%\n",
      "Starting Epoch 8/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 8/30, Loss: 0.1908, Accuracy: 93.66%\n",
      "Validation Loss: 0.6582, Accuracy: 84.08%\n",
      "Starting Epoch 9/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 9/30, Loss: 0.1763, Accuracy: 94.08%\n",
      "Validation Loss: 0.5312, Accuracy: 83.76%\n",
      "Starting Epoch 10/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 10/30, Loss: 0.1685, Accuracy: 94.29%\n",
      "Validation Loss: 0.5860, Accuracy: 85.35%\n",
      "Starting Epoch 11/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 11/30, Loss: 0.1598, Accuracy: 94.40%\n",
      "Validation Loss: 0.6015, Accuracy: 84.24%\n",
      "Starting Epoch 12/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 12/30, Loss: 0.1722, Accuracy: 94.23%\n",
      "Validation Loss: 0.5097, Accuracy: 82.17%\n",
      "Starting Epoch 13/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 13/30, Loss: 0.1345, Accuracy: 95.66%\n",
      "Validation Loss: 0.5473, Accuracy: 85.03%\n",
      "Starting Epoch 14/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 14/30, Loss: 0.1350, Accuracy: 95.28%\n",
      "Validation Loss: 0.7562, Accuracy: 79.14%\n",
      "Starting Epoch 15/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 15/30, Loss: 0.1359, Accuracy: 95.46%\n",
      "Validation Loss: 0.4842, Accuracy: 84.39%\n",
      "Starting Epoch 16/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 16/30, Loss: 0.1359, Accuracy: 95.70%\n",
      "Validation Loss: 0.6945, Accuracy: 84.24%\n",
      "Starting Epoch 17/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 17/30, Loss: 0.1348, Accuracy: 95.45%\n",
      "Validation Loss: 0.5254, Accuracy: 83.76%\n",
      "Starting Epoch 18/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 18/30, Loss: 0.1508, Accuracy: 94.90%\n",
      "Validation Loss: 0.5778, Accuracy: 83.28%\n",
      "Starting Epoch 19/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 19/30, Loss: 0.1195, Accuracy: 95.99%\n",
      "Validation Loss: 0.5317, Accuracy: 86.62%\n",
      "Starting Epoch 20/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 20/30, Loss: 0.1245, Accuracy: 95.73%\n",
      "Validation Loss: 0.7473, Accuracy: 84.24%\n",
      "Starting Epoch 21/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 21/30, Loss: 0.1143, Accuracy: 95.97%\n",
      "Validation Loss: 0.5513, Accuracy: 86.78%\n",
      "Starting Epoch 22/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 22/30, Loss: 0.1164, Accuracy: 95.89%\n",
      "Validation Loss: 0.8260, Accuracy: 81.85%\n",
      "Starting Epoch 23/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 23/30, Loss: 0.1162, Accuracy: 95.93%\n",
      "Validation Loss: 0.5446, Accuracy: 84.24%\n",
      "Starting Epoch 24/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 24/30, Loss: 0.1336, Accuracy: 95.72%\n",
      "Validation Loss: 0.4893, Accuracy: 85.19%\n",
      "Starting Epoch 25/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 25/30, Loss: 0.1136, Accuracy: 96.11%\n",
      "Validation Loss: 0.6561, Accuracy: 86.46%\n",
      "Starting Epoch 26/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 26/30, Loss: 0.1145, Accuracy: 96.12%\n",
      "Validation Loss: 1.0839, Accuracy: 82.01%\n",
      "Starting Epoch 27/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 27/30, Loss: 0.1041, Accuracy: 96.19%\n",
      "Validation Loss: 0.5997, Accuracy: 85.19%\n",
      "Starting Epoch 28/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 28/30, Loss: 0.1266, Accuracy: 95.80%\n",
      "Validation Loss: 2.4405, Accuracy: 81.85%\n",
      "Starting Epoch 29/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 29/30, Loss: 0.0898, Accuracy: 96.82%\n",
      "Validation Loss: 0.5576, Accuracy: 82.17%\n",
      "Starting Epoch 30/30\n",
      "Processing batch 1/1319\n",
      "Processing batch 101/1319\n",
      "Processing batch 201/1319\n",
      "Processing batch 301/1319\n",
      "Processing batch 401/1319\n",
      "Processing batch 501/1319\n",
      "Processing batch 601/1319\n",
      "Processing batch 701/1319\n",
      "Processing batch 801/1319\n",
      "Processing batch 901/1319\n",
      "Processing batch 1001/1319\n",
      "Processing batch 1101/1319\n",
      "Processing batch 1201/1319\n",
      "Processing batch 1301/1319\n",
      "Epoch 30/30, Loss: 0.1086, Accuracy: 96.24%\n",
      "Validation Loss: 0.9287, Accuracy: 83.12%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "print(f\"Total batches: {len(train_dataloader)}\")\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Starting Epoch {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_dataloader):\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Processing batch {batch_idx+1}/{len(train_dataloader)}\")\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / len(train_dataloader)\n",
    "    train_accuracy = (correct / total) * 100\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    val_accuracy = (val_correct / val_total) * 100\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"vggnet19.pth\")\n",
    "print(\"Model saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
