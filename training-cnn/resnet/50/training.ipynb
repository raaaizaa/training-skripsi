{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 2\n",
    "NUM_CLASSES = 9\n",
    "NUM_EPOCHS = 30\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMAGES_SIZE, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.Normalize(MEAN, STD),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(int(IMAGE_SIZE * 1.14)),\n",
    "    transforms.CenterCrop(IMAGE_SIZE),\n",
    "    transforms.Normalize(MEAN, STD),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset_path = \"../../../dataset/train\"\n",
    "val_dataset_path = \"../../../dataset/val\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_dataset_path, transforms=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(root=val_dataset_path, transforms=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    images, labels = next(iter(train_loader))\n",
    "    print(f\"Batch shape: {images.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters, lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # outputs is a tensor: A 2D tensor of shape [batch_size, num_classes].\n",
    "        # Each row contains logits (raw scores) for each class.\n",
    "        # tensor([[1.2, 0.3, 2.5],     # sample 1 → class 2\n",
    "        #        [0.1, 4.1, 0.2]])     # sample 2 → class 1\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        # argmax(dim=1) is find the index of the maximum score \n",
    "        # (the most confident score)\n",
    "        # outputs: (2, 1)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += images.size(0)\n",
    "\n",
    "    calc_loss = running_loss/total\n",
    "    calc_accuracy = correct/total\n",
    "\n",
    "    return calc_loss, calc_accuracy\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += images.size(0)\n",
    "\n",
    "    calc_loss = val_loss/total\n",
    "    calc_accuracy = correct/total\n",
    "\n",
    "    return calc_loss, calc_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = validate(model, train_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}: \")\n",
    "    print(f\"Train loss {train_loss:.4f}, acc {train_acc:.4f} |\")\n",
    "    print(f\"Val loss {val_loss:.4f}, acc {val_acc:.4f}\")\n",
    "    \n",
    "    # checkpoint best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_resnet50.pth\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
