{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 2\n",
    "NORMALIZE_MEAN = [0.485, 0.456, 0.406]\n",
    "NORMALIZE_STD = [0.229, 0.224, 0.225]\n",
    "NUM_CLASSES = 9\n",
    "NUM_EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToNormalize(NORMALIZE_MEAN, NORMALIZE_STD),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(int(IMAGE_SIZE * 1.14)),\n",
    "    transforms.CenterCrop(IMAGE_SIZE),\n",
    "    transforms.Normalize(NORMALIZE_MEAN, NORMALIZE_STD),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset_path = \"../../../dataset/train\"\n",
    "val_dataset_path = \"../../../dataset/val\"\n",
    "train_dataset = datasets.ImageFolder(root=train_dataset_path, transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(root=val_dataset_path, transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     images, labels \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(train_loader))\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBatch shape: \u001b[39m\u001b[39m{\u001b[39;00mimages\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLabel shape: \u001b[39m\u001b[39m{\u001b[39;00mlabels\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    images, labels = next(iter(train_loader))\n",
    "    print(f\"Batch shape: {images.shape}\")\n",
    "    print(f\"Label shape: {labels.shape}\")\n",
    "\n",
    "model = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.IMAGENET1K_V1)\n",
    "\n",
    "\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "old_linear = model.classifier[3]\n",
    "in_feats = old_linear.in_features\n",
    "\n",
    "classifier = nn.Sequential(\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(in_feats, NUM_CLASSES),\n",
    ")\n",
    "model.classifier[3] = classifier\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.classifier.parameters())\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += images.size(0)\n",
    "\n",
    "    return val_loss/total, correct/total\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += images.size(0)\n",
    "\n",
    "    return val_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range (NUM_EPOCHS):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: \"\n",
    "          f\"Train loss {train_loss:.4f}, acc {train_acc:.4f} | \"\n",
    "          f\"Val loss {val_loss:.4f}, acc {val_acc:.4f}\")\n",
    "\n",
    "    # checkpoint best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        now = datetime.now()\n",
    "        model_name = \"./mobilenet/v3/\" + \"mobilenetv3\" + \"-\" + now.strftime(\"%m%d%Y%H%M%S\") \n",
    "        torch.save(model.state_dict(), model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ipyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
