{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torchvision.models as models\n",
                "\n",
                "from torchvision import datasets\n",
                "from torchvision import transforms\n",
                "from torch.utils.data import DataLoader\n",
                "from datetime import datetime"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "NORMALIZE_MEAN = [0.485, 0.456, 0.406]\n",
                "NORMALIZE_STD = [0.229, 0.224, 0.225]\n",
                "\n",
                "IMAGE_SIZE = 224\n",
                "BATCH_SIZE = 16\n",
                "\n",
                "NUM_WORKERS = 2\n",
                "NUM_CLASSES = 9\n",
                "NUM_EPOCHS = 30\n",
                "LEARNING_RATE = 1e-3"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_transforms = transforms.Compose([\n",
                "    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.8, 1.0)),\n",
                "    transforms.RandomHorizontalFlip(),\n",
                "    transforms.RandomVerticalFlip(),\n",
                "    transforms.RandomRotation(15),\n",
                "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize(NORMALIZE_MEAN, NORMALIZE_STD),\n",
                "])\n",
                "\n",
                "val_transforms = transforms.Compose([\n",
                "    transforms.Resize(int(IMAGE_SIZE * 1.14)),\n",
                "    transforms.CenterCrop(IMAGE_SIZE),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize(NORMALIZE_MEAN, NORMALIZE_STD),\n",
                "])\n",
                "\n",
                "train_dataset_path = \"../../../dataset/train\"\n",
                "val_dataset_path = \"../../../dataset/val\"\n",
                "\n",
                "train_dataset = datasets.ImageFolder(root=train_dataset_path, transform=train_transforms)\n",
                "val_dataset = datasets.ImageFolder(root=val_dataset_path, transform=val_transforms)\n",
                "\n",
                "train_loader = DataLoader(\n",
                "    train_dataset,\n",
                "    shuffle=True,\n",
                "    pin_memory=True,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    num_workers=NUM_WORKERS,\n",
                ")\n",
                "\n",
                "val_loader = DataLoader(\n",
                "    val_dataset,\n",
                "    shuffle=False,\n",
                "    pin_memory=True,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    num_workers=NUM_WORKERS,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Batch shape: torch.Size([16, 3, 224, 224])\n",
                        "Label shape: torch.Size([16])\n"
                    ]
                }
            ],
            "source": [
                "if __name__ == \"__main__\":\n",
                "    images, labels = next(iter(train_loader))\n",
                "    print(f\"Batch shape: {images.shape}\")\n",
                "    print(f\"Label shape: {labels.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train(model, loader, optimizer, criterion, device):\n",
                "    model.train()\n",
                "    training_loss, correct, total = 0.0, 0, 0\n",
                "\n",
                "    for images, labels in loader:\n",
                "        images, labels = images.to(device), labels.to(device)\n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(images)\n",
                "        loss = criterion(outputs, labels)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "\n",
                "        training_loss += loss.item() * images.size(0)\n",
                "        preds = outputs.argmax(dim=1)\n",
                "        correct += (preds == labels).sum().item()\n",
                "        total += images.size(0)\n",
                "    \n",
                "    avg_loss = training_loss/total\n",
                "    avg_accuracy = correct/total\n",
                "\n",
                "    return avg_loss, avg_accuracy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "def validate(model, loader, criterion, device):\n",
                "    model.eval()\n",
                "    validate_loss, correct, total = 0.0, 0, 0\n",
                "\n",
                "    with torch.no_grad():\n",
                "        for images, labels in loader:\n",
                "            images, labels = images.to(device), labels.to(device)\n",
                "            outputs = model(images)\n",
                "            loss = criterion(outputs, labels)\n",
                "\n",
                "            validate_loss += loss.item() * images.size(0)\n",
                "            preds = outputs.argmax(dim=1)\n",
                "            correct += (preds == labels).sum().item()\n",
                "            total += images.size(0)\n",
                "    \n",
                "    avg_loss = validate_loss/total\n",
                "    avg_accuracy = correct/total\n",
                "\n",
                "    return avg_loss, avg_accuracy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "MobileNetV3(\n",
                            "  (features): Sequential(\n",
                            "    (0): Conv2dNormActivation(\n",
                            "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
                            "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "      (2): Hardswish()\n",
                            "    )\n",
                            "    (1): InvertedResidual(\n",
                            "      (block): Sequential(\n",
                            "        (0): Conv2dNormActivation(\n",
                            "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
                            "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): ReLU(inplace=True)\n",
                            "        )\n",
                            "        (1): Conv2dNormActivation(\n",
                            "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "        )\n",
                            "      )\n",
                            "    )\n",
                            "    (2): InvertedResidual(\n",
                            "      (block): Sequential(\n",
                            "        (0): Conv2dNormActivation(\n",
                            "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): ReLU(inplace=True)\n",
                            "        )\n",
                            "        (1): Conv2dNormActivation(\n",
                            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
                            "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): ReLU(inplace=True)\n",
                            "        )\n",
                            "        (2): Conv2dNormActivation(\n",
                            "          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "        )\n",
                            "      )\n",
                            "    )\n",
                            "    (3): InvertedResidual(\n",
                            "      (block): Sequential(\n",
                            "        (0): Conv2dNormActivation(\n",
                            "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): ReLU(inplace=True)\n",
                            "        )\n",
                            "        (1): Conv2dNormActivation(\n",
                            "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
                            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): ReLU(inplace=True)\n",
                            "        )\n",
                            "        (2): Conv2dNormActivation(\n",
                            "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "        )\n",
                            "      )\n",
                            "    )\n",
                            "    (4): InvertedResidual(\n",
                            "      (block): Sequential(\n",
                            "        (0): Conv2dNormActivation(\n",
                            "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): ReLU(inplace=True)\n",
                            "        )\n",
                            "        (1): Conv2dNormActivation(\n",
                            "          (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
                            "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): ReLU(inplace=True)\n",
                            "        )\n",
                            "        (2): SqueezeExcitation(\n",
                            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "          (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
                            "          (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
                            "          (activation): ReLU()\n",
                            "          (scale_activation): Hardsigmoid()\n",
                            "        )\n",
                            "        (3): Conv2dNormActivation(\n",
                            "          (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "        )\n",
                            "      )\n",
                            "    )\n",
                            "    (5): InvertedResidual(\n",
                            "      (block): Sequential(\n",
                            "        (0): Conv2dNormActivation(\n",
                            "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): ReLU(inplace=True)\n",
                            "        )\n",
                            "        (1): Conv2dNormActivation(\n",
                            "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
                            "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): ReLU(inplace=True)\n",
                            "        )\n",
                            "        (2): SqueezeExcitation(\n",
                            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
                            "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
                            "          (activation): ReLU()\n",
                            "          (scale_activation): Hardsigmoid()\n",
                            "        )\n",
                            "        (3): Conv2dNormActivation(\n",
                            "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "        )\n",
                            "      )\n",
                            "    )\n",
                            "    (6): InvertedResidual(\n",
                            "      (block): Sequential(\n",
                            "        (0): Conv2dNormActivation(\n",
                            "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): ReLU(inplace=True)\n",
                            "        )\n",
                            "        (1): Conv2dNormActivation(\n",
                            "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
                            "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): ReLU(inplace=True)\n",
                            "        )\n",
                            "        (2): SqueezeExcitation(\n",
                            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
                            "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
                            "          (activation): ReLU()\n",
                            "          (scale_activation): Hardsigmoid()\n",
                            "        )\n",
                            "        (3): Conv2dNormActivation(\n",
                            "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "        )\n",
                            "      )\n",
                            "    )\n",
                            "    (7): InvertedResidual(\n",
                            "      (block): Sequential(\n",
                            "        (0): Conv2dNormActivation(\n",
                            "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): Hardswish()\n",
                            "        )\n",
                            "        (1): Conv2dNormActivation(\n",
                            "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
                            "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): Hardswish()\n",
                            "        )\n",
                            "        (2): Conv2dNormActivation(\n",
                            "          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "        )\n",
                            "      )\n",
                            "    )\n",
                            "    (8): InvertedResidual(\n",
                            "      (block): Sequential(\n",
                            "        (0): Conv2dNormActivation(\n",
                            "          (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): Hardswish()\n",
                            "        )\n",
                            "        (1): Conv2dNormActivation(\n",
                            "          (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
                            "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): Hardswish()\n",
                            "        )\n",
                            "        (2): Conv2dNormActivation(\n",
                            "          (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "        )\n",
                            "      )\n",
                            "    )\n",
                            "    (9): InvertedResidual(\n",
                            "      (block): Sequential(\n",
                            "        (0): Conv2dNormActivation(\n",
                            "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): Hardswish()\n",
                            "        )\n",
                            "        (1): Conv2dNormActivation(\n",
                            "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
                            "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): Hardswish()\n",
                            "        )\n",
                            "        (2): Conv2dNormActivation(\n",
                            "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "        )\n",
                            "      )\n",
                            "    )\n",
                            "    (10): InvertedResidual(\n",
                            "      (block): Sequential(\n",
                            "        (0): Conv2dNormActivation(\n",
                            "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): Hardswish()\n",
                            "        )\n",
                            "        (1): Conv2dNormActivation(\n",
                            "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
                            "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): Hardswish()\n",
                            "        )\n",
                            "        (2): Conv2dNormActivation(\n",
                            "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "        )\n",
                            "      )\n",
                            "    )\n",
                            "    (11): InvertedResidual(\n",
                            "      (block): Sequential(\n",
                            "        (0): Conv2dNormActivation(\n",
                            "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): Hardswish()\n",
                            "        )\n",
                            "        (1): Conv2dNormActivation(\n",
                            "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
                            "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): Hardswish()\n",
                            "        )\n",
                            "        (2): SqueezeExcitation(\n",
                            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "          (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
                            "          (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
                            "          (activation): ReLU()\n",
                            "          (scale_activation): Hardsigmoid()\n",
                            "        )\n",
                            "        (3): Conv2dNormActivation(\n",
                            "          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "        )\n",
                            "      )\n",
                            "    )\n",
                            "    (12): InvertedResidual(\n",
                            "      (block): Sequential(\n",
                            "        (0): Conv2dNormActivation(\n",
                            "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): Hardswish()\n",
                            "        )\n",
                            "        (1): Conv2dNormActivation(\n",
                            "          (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
                            "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): Hardswish()\n",
                            "        )\n",
                            "        (2): SqueezeExcitation(\n",
                            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
                            "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
                            "          (activation): ReLU()\n",
                            "          (scale_activation): Hardsigmoid()\n",
                            "        )\n",
                            "        (3): Conv2dNormActivation(\n",
                            "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "        )\n",
                            "      )\n",
                            "    )\n",
                            "    (13): InvertedResidual(\n",
                            "      (block): Sequential(\n",
                            "        (0): Conv2dNormActivation(\n",
                            "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): Hardswish()\n",
                            "        )\n",
                            "        (1): Conv2dNormActivation(\n",
                            "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
                            "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): Hardswish()\n",
                            "        )\n",
                            "        (2): SqueezeExcitation(\n",
                            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
                            "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
                            "          (activation): ReLU()\n",
                            "          (scale_activation): Hardsigmoid()\n",
                            "        )\n",
                            "        (3): Conv2dNormActivation(\n",
                            "          (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "        )\n",
                            "      )\n",
                            "    )\n",
                            "    (14): InvertedResidual(\n",
                            "      (block): Sequential(\n",
                            "        (0): Conv2dNormActivation(\n",
                            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): Hardswish()\n",
                            "        )\n",
                            "        (1): Conv2dNormActivation(\n",
                            "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
                            "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): Hardswish()\n",
                            "        )\n",
                            "        (2): SqueezeExcitation(\n",
                            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
                            "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
                            "          (activation): ReLU()\n",
                            "          (scale_activation): Hardsigmoid()\n",
                            "        )\n",
                            "        (3): Conv2dNormActivation(\n",
                            "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "        )\n",
                            "      )\n",
                            "    )\n",
                            "    (15): InvertedResidual(\n",
                            "      (block): Sequential(\n",
                            "        (0): Conv2dNormActivation(\n",
                            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): Hardswish()\n",
                            "        )\n",
                            "        (1): Conv2dNormActivation(\n",
                            "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
                            "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "          (2): Hardswish()\n",
                            "        )\n",
                            "        (2): SqueezeExcitation(\n",
                            "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
                            "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
                            "          (activation): ReLU()\n",
                            "          (scale_activation): Hardsigmoid()\n",
                            "        )\n",
                            "        (3): Conv2dNormActivation(\n",
                            "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "        )\n",
                            "      )\n",
                            "    )\n",
                            "    (16): Conv2dNormActivation(\n",
                            "      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "      (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
                            "      (2): Hardswish()\n",
                            "    )\n",
                            "  )\n",
                            "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "  (classifier): Sequential(\n",
                            "    (0): Linear(in_features=960, out_features=1280, bias=True)\n",
                            "    (1): Hardswish()\n",
                            "    (2): Dropout(p=0.2, inplace=True)\n",
                            "    (3): Sequential(\n",
                            "      (0): Dropout(p=0.3, inplace=False)\n",
                            "      (1): Linear(in_features=1280, out_features=9, bias=True)\n",
                            "    )\n",
                            "  )\n",
                            ")"
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.IMAGENET1K_V1)\n",
                "\n",
                "for param in model.features.parameters():\n",
                "    param.requires_grad = False\n",
                "\n",
                "old_linear = model.classifier[3]\n",
                "in_feats = old_linear.in_features\n",
                "\n",
                "classifier = nn.Sequential(\n",
                "    nn.Dropout(0.3),\n",
                "    nn.Linear(in_feats, NUM_CLASSES),\n",
                ")\n",
                "model.classifier[3] = classifier\n",
                "\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "model.to(device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=LEARNING_RATE)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/30: Train loss 1.1758, acc 0.6425 | Val   loss 0.5885, acc 0.8343\n",
                        "Epoch 2/30: Train loss 0.6266, acc 0.7992 | Val   loss 0.4140, acc 0.8737\n",
                        "Epoch 3/30: Train loss 0.5190, acc 0.8256 | Val   loss 0.3738, acc 0.8626\n",
                        "Epoch 4/30: Train loss 0.4578, acc 0.8476 | Val   loss 0.2980, acc 0.9000\n",
                        "Epoch 5/30: Train loss 0.4349, acc 0.8552 | Val   loss 0.2963, acc 0.8960\n",
                        "Epoch 6/30: Train loss 0.3888, acc 0.8727 | Val   loss 0.2657, acc 0.9081\n",
                        "Epoch 7/30: Train loss 0.3776, acc 0.8707 | Val   loss 0.2673, acc 0.9091\n",
                        "Epoch 8/30: Train loss 0.3547, acc 0.8789 | Val   loss 0.2568, acc 0.9061\n",
                        "Epoch 9/30: Train loss 0.3560, acc 0.8776 | Val   loss 0.2498, acc 0.9081\n",
                        "Epoch 10/30: Train loss 0.3431, acc 0.8761 | Val   loss 0.2322, acc 0.9192\n",
                        "Epoch 11/30: Train loss 0.3242, acc 0.8887 | Val   loss 0.2279, acc 0.9152\n",
                        "Epoch 12/30: Train loss 0.3327, acc 0.8876 | Val   loss 0.2232, acc 0.9253\n",
                        "Epoch 13/30: Train loss 0.3225, acc 0.8852 | Val   loss 0.2292, acc 0.9162\n",
                        "Epoch 14/30: Train loss 0.3120, acc 0.8898 | Val   loss 0.2078, acc 0.9283\n",
                        "Epoch 15/30: Train loss 0.3060, acc 0.8958 | Val   loss 0.2279, acc 0.9202\n",
                        "Epoch 16/30: Train loss 0.2942, acc 0.8973 | Val   loss 0.2340, acc 0.9202\n",
                        "Epoch 17/30: Train loss 0.2804, acc 0.9042 | Val   loss 0.2082, acc 0.9212\n",
                        "Epoch 18/30: Train loss 0.3026, acc 0.8941 | Val   loss 0.2121, acc 0.9232\n",
                        "Epoch 19/30: Train loss 0.2748, acc 0.9038 | Val   loss 0.2032, acc 0.9253\n",
                        "Epoch 20/30: Train loss 0.2726, acc 0.9090 | Val   loss 0.2107, acc 0.9202\n",
                        "Epoch 21/30: Train loss 0.2731, acc 0.9045 | Val   loss 0.1944, acc 0.9323\n",
                        "Epoch 22/30: Train loss 0.2628, acc 0.9083 | Val   loss 0.1927, acc 0.9323\n",
                        "Epoch 23/30: Train loss 0.2636, acc 0.9066 | Val   loss 0.1950, acc 0.9293\n",
                        "Epoch 24/30: Train loss 0.2510, acc 0.9114 | Val   loss 0.2029, acc 0.9323\n",
                        "Epoch 25/30: Train loss 0.2469, acc 0.9101 | Val   loss 0.1857, acc 0.9323\n",
                        "Epoch 26/30: Train loss 0.2482, acc 0.9137 | Val   loss 0.1866, acc 0.9313\n",
                        "Epoch 27/30: Train loss 0.2297, acc 0.9168 | Val   loss 0.1749, acc 0.9394\n",
                        "Epoch 28/30: Train loss 0.2283, acc 0.9189 | Val   loss 0.1736, acc 0.9343\n",
                        "Epoch 29/30: Train loss 0.2341, acc 0.9127 | Val   loss 0.1687, acc 0.9364\n",
                        "Epoch 30/30: Train loss 0.2349, acc 0.9163 | Val   loss 0.1721, acc 0.9303\n"
                    ]
                }
            ],
            "source": [
                "best_val_loss = float('inf')\n",
                "\n",
                "for epoch in range (NUM_EPOCHS):\n",
                "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
                "    validate_loss, val_acc = validate(model, val_loader, criterion, device)\n",
                "\n",
                "    print(\n",
                "        f\"Epoch {epoch+1}/{NUM_EPOCHS}: \"\n",
                "        f\"Train loss {train_loss:.4f}, acc {train_acc:.4f} | \"\n",
                "        f\"Val loss {validate_loss:.4f}, acc {val_acc:.4f}\"\n",
                "    )\n",
                "\n",
                "    # checkpoint best model\n",
                "    if validate_loss < best_val_loss:\n",
                "        best_val_loss = validate_loss\n",
                "\n",
                "        now = datetime.now()\n",
                "        model_name = \"./mobilenet/v3/\" + \"mobilenetv3\" + \"-\" + now.strftime(\"%m%d%Y%H%M%S\") \n",
                "\n",
                "        torch.save(model.state_dict(), model_name)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv (3.12.3)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}